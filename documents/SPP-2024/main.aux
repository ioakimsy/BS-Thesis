\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{knight2018peer}
\citation{crouch2001peer}
\citation{crouch2001peer,smith2009peer}
\citation{lasry2008peer}
\citation{smith2009peer}
\citation{lasry2008peer}
\citation{weisstein2002cellular}
\citation{louis2018probabilistic}
\citation{roxas2010seating}
\citation{roxas2010seating}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{2}{section.2}\protected@file@percent }
\newlabel{sec:methods}{{2}{2}{Methodology}{section.2}{}}
\newlabel{eq:Lambda matrix}{{1}{2}{Methodology}{equation.2.1}{}}
\newlabel{eq:learning probability}{{2}{2}{Methodology}{equation.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results and Discussion}{2}{section.3}\protected@file@percent }
\citation{roxas2010seating}
\citation{roxas2010seating}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:m-48}{{1a}{3}{Subfigure 1a}{subfigure.1.1}{}}
\newlabel{sub@fig:m-48}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{fig:m-96}{{1b}{3}{Subfigure 1b}{subfigure.1.2}{}}
\newlabel{sub@fig:m-96}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\newlabel{fig:t-48}{{1c}{3}{Subfigure 1c}{subfigure.1.3}{}}
\newlabel{sub@fig:t-48}{{(c)}{c}{Subfigure 1c\relax }{subfigure.1.3}{}}
\newlabel{fig:t-96}{{1d}{3}{Subfigure 1d}{subfigure.1.4}{}}
\newlabel{sub@fig:t-96}{{(d)}{d}{Subfigure 1d\relax }{subfigure.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example plots for characteristic variable ($m$) (higher is better) and time to learn ($T$) (lower is better) vs. Spread coefficient ($\lambda $) for classroom length $L \in \lbrace 48,96 \rbrace $.}}{3}{figure.caption.1}\protected@file@percent }
\newlabel{fig:TTL and m vs lambda}{{1}{3}{Example plots for characteristic variable ($m$) (higher is better) and time to learn ($T$) (lower is better) vs. Spread coefficient ($\lambda $) for classroom length $L \in \lbrace 48,96 \rbrace $}{figure.caption.1}{}}
\bibstyle{spp-bst}
\bibdata{bibfile}
\bibcite{knight2018peer}{{1}{2018}{{Knight and Brame}}{{}}}
\bibcite{crouch2001peer}{{2}{2001}{{Crouch and Mazur}}{{}}}
\bibcite{smith2009peer}{{3}{2009}{{Smith et~al.}}{{Smith, Wood, Adams, Wieman, Knight, Guild, and Su}}}
\bibcite{lasry2008peer}{{4}{2008}{{Lasry et~al.}}{{Lasry, Mazur, and Watkins}}}
\bibcite{weisstein2002cellular}{{5}{2002}{{Weisstein}}{{}}}
\bibcite{louis2018probabilistic}{{6}{2018}{{Louis and Nardi}}{{}}}
\bibcite{roxas2010seating}{{7}{2010}{{Roxas et~al.}}{{Roxas, Carreon-Monterola, and Monterola}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Maximum time $t_{max}$ vs class size $N$ for P2P and traditional models (lower is better). Circular symbols denote data points for the inner corner configuration for P2P learning. Rectangular denote the data points for traditional learning model. The dash lines are the power law fit in the form of $t_{max}=a \cdot N^b$ using three $\lambda $ values, $\lambda \in \lbrace 0.1, 0.5, 0.9 \rbrace $ for two cases: (1) peer-to-peer learning (inner corner configuration), and (2) traditional learning . The two major groups of power law fits are obtained based on the exponent $b$: (a) inner corner, $b = 0.432 \pm 0.019$, (b) traditional, $b=0.087\pm 0.021$. The table contains the power law parameters $a$ and $b$ for each set of parameters. }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:tmax vs N}{{2}{4}{Maximum time $t_{max}$ vs class size $N$ for P2P and traditional models (lower is better). Circular symbols denote data points for the inner corner configuration for P2P learning. Rectangular denote the data points for traditional learning model. The dash lines are the power law fit in the form of $t_{max}=a \cdot N^b$ using three $\lambda $ values, $\lambda \in \lbrace 0.1, 0.5, 0.9 \rbrace $ for two cases: (1) peer-to-peer learning (inner corner configuration), and (2) traditional learning . The two major groups of power law fits are obtained based on the exponent $b$: (a) inner corner, $b = 0.432 \pm 0.019$, (b) traditional, $b=0.087\pm 0.021$. The table contains the power law parameters $a$ and $b$ for each set of parameters}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusions}{4}{section.4}\protected@file@percent }
\gdef \@abspage@last{4}
