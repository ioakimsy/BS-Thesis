begin
    using Pkg
    Pkg.activate(".")

    #! Pkg.add() is in 2DBPCA-simulation
    #Pkg.update()

    using Random
    using Statistics
    using DelimitedFiles
    using CSV
    using DataFrames
    using LsqFit
    using BenchmarkTools
    using ProfileView
    using Profile
    using Alert
    using ProgressMeter
end

function initiate_grid(L::Int=8)
	#type should be ::Symbol. Symbol is :xyz
    if L%2 == 1
        L=L+1
    end

    grid = zeros(Int,L,L)
    return grid
end

function initiate_λ_grid(size, λ₀, δ)
    λ = [λ₀ + δ, λ₀ - δ]
    rands = rand(size, size)
    grid = zeros(Float64, size, size)
    grid[rands .< 0.5] .= λ[1]
    grid[rands .>= 0.5] .= λ[2]
    return grid
end

function generate_next_generation(initial_grid::Matrix{Int},ρ::Float64, initial_λ_grid::Matrix{Float64})
    #=
    * Parameter descriptions:
        * This function uses the initial grid of students' states and the spread matrix (ρ) to generate the next generate_next_generation
        * The initial grid of student states should be an even-sided matrix with values 0 or 1 (only). This can be generated by the initial_grid() function 
        * ρ should be an odd-sided square matrix where each element can have values between 0 and 1

    TODO: adjust the learning probability to account for non-uniform individual learning rate
    TODO: make a probability of unlearning for each student
    TODO: profile the function to identify bottlenecks
    =#

    grid = initial_grid
    next_gen = zeros(Int64, size(grid))
	
    for col in 1:size(initial_grid)[1], row in 1:size(initial_grid)[2]

        if grid[row,col] == 1
            next_gen[row,col] = 1
            continue
        end

        learn_prob = ρ * initial_λ_grid[row,col]

        random_number = rand()

        if random_number <= learn_prob
            next_gen[row,col] = 1
        end
        
    end
    return next_gen
	
end


function simulate_steady_state(class_length, ρ, steady_state_tolerance, δλ; λ₀=0.5)
    #=
    * simulate_steady_state() keeps generating new generation until steady state is reached
    * The system is considered to be at steady state when there has been no changes in steady_state_tolerance generations
    =#
	initial_class = initiate_grid(class_length)
    λ_grid = initiate_λ_grid(class_length, λ₀, δλ)
	generations = [initial_class]
	
	steady_state = false
	num_generations = 1

	while steady_state == false
        next_gen = generate_next_generation(generations[end],ρ,λ_grid)	
        push!(generations, next_gen)
        num_generations = num_generations + 1
		
		if generations[end] == generations[max(1,num_generations-steady_state_tolerance)] && num_generations > steady_state_tolerance
			steady_state = true
		end
		
	end

	generations = generations[begin:end-steady_state_tolerance]

	num_generations = length(generations)
	
	return generations, num_generations, λ_grid
end

function generate_directories(lengths::Vector{Int}, Ρs::Vector{Float64},δλs::Vector{Float64}, steady_state_tolerance::Int, n_trials::Int; λ₀=0.5)
    folders = ["images", "data"]
    for length in lengths, ρ in Ρs, folder in folders, trial in 1:n_trials, δλ in δλs

            mkpath("./output/2D-Binary-PCA-IH/traditional-$(length)/$(ρ)-$(λ₀)-$(δλ)/trial_$(trial)/$(folder)")
            
    end
end

function class_simulation(lengths::Vector{Int}, Ρs::Vector{Float64}, δλs::Vector{Float64}, steady_state_tolerance::Int, n_trials::Int; λ₀=0.5)
    
    max_iters = prod([length(x) for x in [lengths,Ρs,δλs]]) * n_trials
    prog_bar = Progress(max_iters; showspeed=true)
    
    @. model(x,p) = p[1] * x ^ p[2]

   for trial in 1:n_trials
        for ρ₀ in Ρs, class_length in lengths, δλ in δλs#, trial in 1:n_trials

            #println("$seat_config 	$ρ₀ 	$class_size 	$trial")

            generations, num_generations, λ_grid = simulate_steady_state(class_length, ρ₀, steady_state_tolerance, δλ; λ₀=λ₀)

            #* Saving raw data
            df_cols = ["Generation $(i)" for i in 1:num_generations]
            df_data = vec.(generations)

            #* row = ith student; column = jth generation
            student_states_df = DataFrame(df_data,df_cols)

            CSV.write("./output/2D-Binary-PCA-IH/traditional-$(class_length)/$(ρ₀)-$(λ₀)-$(δλ)/trial_$(trial)/data/2DBPCAIH-traditional-$(class_length)-$(ρ₀)-$(λ₀)-$(δλ)-trial_$(trial)-data.csv",student_states_df)
            CSV.write("./output/2D-Binary-PCA-IH/traditional-$(class_length)/$(ρ₀)-$(λ₀)-$(δλ)/trial_$(trial)/data/2DBPCAIH-traditional-$(class_length)-$(ρ₀)-$(λ₀)-$(δλ)-trial_$(trial)-lambda_grid.csv", DataFrame(λ_grid, :auto))

            #* Normalized to percent of classroom learned
            learned = map(x->sum(x), generations)
            learned = learned ./ maximum(learned; init=1) 
            
            #! makes the output of the maximum 1 when there is no maximum resulting into non-normalized values
            #! it broke once, i do not know why
            
            #* Set up in case need to truncate outliers
            #* Only considers first 25% of the data
            learned_y = learned[1:end-Int64(floor(0.75*num_generations))]
            generation_domain = 1:length(learned_y)

            #* axᵇ where power_coeffs are (a,b)
            fit = curve_fit(model, generation_domain, learned_y, [0.25,2.0], lower = [0.,0.], upper = [1.,5.])
            power_coeffs = coef(fit)
            #standard_errors = stderror(fit)

            #* Writing parameters to CSV file; 
            #! Will break if length of generation is longer than length of fit coeffs (2 for power fit) - verly likely not to happen
            #* power_fit column for the dataframe would be: a, b, σₐ, σᵦ
            fit_params_df = DataFrame(
                learned_per_gen = learned,
                power_fit = [power_coeffs...; [missing for _ in 1:num_generations-length(power_coeffs)]],
            )
   
            CSV.write("./output/2D-Binary-PCA-IH/traditional-$(class_length)/$(ρ₀)-$(λ₀)-$(δλ)/trial_$(trial)/data/2DBPCAIH-traditional-$(class_length)-$(ρ₀)-$(λ₀)-$(δλ)-trial_$(trial)-fit_params.csv", fit_params_df)

            ProgressMeter.next!(prog_bar, 
                showvalues = [("ρ₀", ρ₀), ("Class size", class_length), ("Trial", trial)]
            )
        end
    end
end

#! Main
begin
	# List of parameters
    #TODO: move list of parameters to external file to be read to sync across the scripts
    lengths = [32,48,64,96,128]
	Ρs = collect(0.1:0.1:1)
    δλs = collect(0.0:0.1:0.4)
	steady_state_tolerance = 20
	n_trials = 20
    λ₀ = 0.5

	generate_directories(lengths,
        Ρs,
        δλs,
        steady_state_tolerance,
        n_trials;
        λ₀ = λ₀
	)
	
	@alert class_simulation(lengths,
		Ρs,
        δλs,
		steady_state_tolerance,
		n_trials;
        λ₀=λ₀
	)
end